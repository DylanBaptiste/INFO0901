{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import *\n",
    "\n",
    "# Setup Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "# Setup numpy, pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Setup matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "DEFAULT_W, DEFAULT_H = (16, 9)\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [DEFAULT_W, DEFAULT_H]\n",
    "matplotlib.rcParams[\"font.size\"] = 15\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Load data\n",
    "FILE_NAME = \"winequality_white.csv\"\n",
    "Y_COL_NAME = \"quality\"\n",
    "data = pd.read_csv(FILE_NAME, sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Distribution et informations statistiques de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Standard Pearson deviation\n",
    "\n",
    "print('Mean values for each variable\\n{}\\n'.format(data.mean()))\n",
    "print('Median values for each variable\\n{}\\n'.format(data.median()))\n",
    "print('Modes for each variable\\n{}\\n'.format(data.mode()))\n",
    "print('Standard Pearson deviation values for each variable\\n{}\\n'.format(data.std()))\n",
    "\n",
    "# Boxplot for each variable grouped by the quality values\n",
    "columns=data.columns.drop(['quality'])\n",
    "\n",
    "for column in columns:\n",
    "    data.boxplot(column=column, by='quality')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - distribution\n",
    "# - (FAIT) matrice de correlation (pearson correlation)\n",
    "# std, mean, boite moustache etc...\n",
    "# distribution par note\n",
    "\n",
    "data.describe()\n",
    "\n",
    "corr = data.corr(method='pearson')\n",
    "display(corr.style.background_gradient(cmap='coolwarm').set_precision(2))\n",
    "# classement:\n",
    "# top = abs(corr.loc[Y_COL_NAME]).sort_values(ascending=False)\n",
    "top = corr.loc[Y_COL_NAME][corr.index != Y_COL_NAME]\n",
    "sorted = abs(top).sort_values(ascending=False)\n",
    "display(top) # en abs car -1 donne une bonne correlation aussi (correlation negative)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x=sorted.index, height=top[sorted.index], width=1, edgecolor='black')\n",
    "ax.set_title(\"Classement des correlations des variables par rapport à la variable \\\"quality\\\"\", fontdict={\"size\":25})\n",
    "for i, v in enumerate(top[sorted.index].values):\n",
    "    ax.text(i - 0.25, (v + np.sign(v) * 0.015) - 0.01, f\"{round(v, 2):.2f}\", color='black')\n",
    "# plt.axhline(1, linestyle='--')\n",
    "# plt.axhline(-1, linestyle='--')\n",
    "plt.ylabel(\"Pearson correlation\", fontweight='light', fontsize='x-large')\n",
    "plt.xticks(rotation=67.5, horizontalalignment='right', fontweight='light', fontsize='large')\n",
    "plt.yticks(fontweight='light', fontsize='small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASS = 10\n",
    "\n",
    "X = data.loc[:, data.columns != Y_COL_NAME]\n",
    "# X = ((X - X.mean()) / X.std()).values # Standardization colonne par colonne # (x - µ) / σ\n",
    "# ou\n",
    "X = ((X - X.min()) / (X.max() - X.min())).values # min-max scaling => 0 - 1 # (x - min) / (max - min)\n",
    "# Jmais compris c'etait quoi le mieux : https://kharshit.github.io/blog/2018/03/23/scaling-vs-normalization\n",
    "\n",
    "Y = data.loc[:, Y_COL_NAME].values\n",
    "Y = Y.reshape(-1, 1) # Y est scale entre 0 et 1 au moment de faire la regression (on garde les notes en entier pour le model de classif)\n",
    "\n",
    "NB_INPUT = X.shape[1] # nombre de variable en input des modeles\n",
    "NB_DATA = X.shape[0]\n",
    "# X, Y, X.shape, Y.shape\n",
    "\n",
    "# Split train/test/validation\n",
    "pTrain, pTest, pValidation = (0.80, 0.10, 0.10)\n",
    "assert (pTrain + pTest + pValidation) == 1.0, f\"La somme doit etre equel à 1, {pTrain, pTest, pValidation}\"\n",
    "SPLIT_TRAIN = int(NB_DATA * pTrain)\n",
    "SPLIT_TEST = int(NB_DATA * pTest)\n",
    "SPLIT_VAL = int(NB_DATA * pValidation)\n",
    "print(SPLIT_TRAIN, SPLIT_TEST, SPLIT_VAL)\n",
    "X_train, X_test, X_val = X[:SPLIT_TRAIN], X[SPLIT_TRAIN:SPLIT_TRAIN+SPLIT_TEST], X[-SPLIT_VAL:]\n",
    "Y_train, Y_test, Y_val = Y[:SPLIT_TRAIN], Y[SPLIT_TRAIN:SPLIT_TRAIN+SPLIT_TEST], Y[-SPLIT_VAL:]\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(Y_train.shape, Y_test.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "\tinput = Input(shape=(NB_INPUT,), name=\"input\")\n",
    "\tx = Dense(1000, activation=\"relu\")(input)\n",
    "\tx = Dropout(0.2)(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(500, activation=\"relu\")(x)\n",
    "\tx = Dropout(0.2)(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dense(250, activation=\"relu\")(x)\n",
    "\tx = Dropout(0.2)(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\toutput = Dense(NB_CLASS, activation=Softmax(), name=\"prediction\")(x)\n",
    "\t\n",
    "\treturn Model(input, output, name=\"classification_model\")\n",
    "\n",
    "# regression_model().summary()\n",
    "# classification_model().summary()\n",
    "\n",
    "# yt, yp = tf.constant([0,1,2,3,4,5,6,7,8,9]) / 10, tf.constant([0.05,0.0,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "# print(yt, yp)\n",
    "# regression_accuracy(yt, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModel = classification_model()\n",
    "classModel.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=Adam(learning_rate=0.0001))\n",
    "classModel.summary()\n",
    "\n",
    "hclass = classModel.fit(X_train, Y_train, validation_data=[X_test, Y_test], batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(hclass.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(hclass.history[\"val_loss\"], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(hclass.history[\"accuracy\"], label=\"train accuracy\")\n",
    "plt.plot(hclass.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(hclass.history[\"val_loss\"]) / np.array(hclass.history[\"loss\"]), label=\"ratio test/train loss\")\n",
    "plt.axhline(y=1, color='b', linestyle='--', label=\"Equilibre\")\n",
    "plt.legend()\n",
    "# Pour evaluer le surapprentissage (plus on s'eloigne de 1 en positif plus on est en surapprentisssage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "Y_pred = np.argmax(classModel.predict(X_train), axis=1)\n",
    "Y_true = Y_train.reshape(-1,)\n",
    "cm = confusion_matrix(Y_true, Y_pred, labels=np.arange(0, 10))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='g')\n",
    "plt.show()\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(classModel.predict(X_test), axis=1)\n",
    "Y_true = Y_test.reshape(-1,)\n",
    "cm = confusion_matrix(Y_true, Y_pred, labels=np.arange(0, 10))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='g')\n",
    "plt.show()\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Cross Val pour test different meta parametre\n",
    "# plot les resultats + leur std par epochs\n",
    "\n",
    "# TODO tester l'accuracy de la classif en faisant apparaitre aussi le seconde choix du model\n",
    "# possible aussi de regarder si les deux premier choix sont \"proche\" (cad si une prediction à 5 en choix 1 est suivit par un 4 ou 6 en choix 2 (faisable en faaisant mean(abs(choix1-choix2)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Conclure\n",
    "# TODO souligner les limites du dataset: que 3 votants, manque d'element en input comme le prix, les labels de qualité etc pour que le model soit pertinent dans le cadre d'une utilisation de classification de vin en situation de vente reel"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d30491a918b2bb80bddb8df1507fb40d67bf864fa8abf51b7fc41f1e6d55db91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
